{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"title\">Deep Neural Networks</div>\n",
    "<div class=\"subtitle\">Métodos Avanzados en Aprendizaje Automático</div>\n",
    "<div class=\"author\">Carlos María Alaíz Gudín - Universidad Autónoma de Madrid</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines the configuration of Jupyter Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<head><link rel=\"stylesheet\" href=\"style.css\"></head>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<head><link rel=\"stylesheet\" href=\"style.css\"></head>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell imports the packages to be used (all of them quite standard except for `Utils`, which is provided with the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_sample_images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "from tensorflow import keras\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "matplotlib.rc(\"figure\", figsize=(15, 5))\n",
    "matplotlib.rc(\"image\", cmap=\"gray\")\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset will be used to illustrate the autoencoders.\n",
    "This dataset is composed by hand-written digits of $28 \\times 28$ pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_tr, y_tr), (x_te, y_te) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Number of axis:   \", x_tr.ndim)\n",
    "print(\"Dimension (train):\", x_tr.shape)\n",
    "print(\"Dimension (test): \", x_te.shape)\n",
    "print(\"Data type:        \", x_tr.dtype)\n",
    "\n",
    "plt.imshow(x_tr[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# The pixels are transformed to the interval [0, 1].\n",
    "x_tr = x_tr.astype(\"float32\") / 255.\n",
    "x_te = x_te.astype(\"float32\") / 255.\n",
    "\n",
    "# Each image is converted into a 1-dimensional vector.\n",
    "x_tr_1D = x_tr.reshape(len(x_tr), -1)\n",
    "x_te_1D = x_te.reshape(len(x_te), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To build an AE in Keras the architecture should be specified:\n",
    "    * Input layer, corresponding to the data to be encoded.\n",
    "    * Encoder layers, which will compress the information.\n",
    "    * Decoder layers, which will decompress the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_builder(inp_lay, enc_lays, dec_lays, optimizer=\"adam\"):\n",
    "    # AE.\n",
    "    autoencoder = keras.Sequential([inp_lay] + enc_lays + dec_lays)\n",
    "    autoencoder.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "    # Encoder.\n",
    "    encoder = keras.Sequential([inp_lay] + enc_lays)\n",
    "\n",
    "    # Decoder.\n",
    "    decoder = keras.Sequential([keras.Input(shape=enc_lays[-1].output_shape[1:])] + dec_lays)\n",
    "\n",
    "    return [autoencoder, encoder, decoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first approach to guarantee the information compression is forcing th ehidden layer to be much smaller than the input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 16\n",
    "\n",
    "inp_lay = keras.Input(shape=(x_tr_1D.shape[1],))\n",
    "enc_lays = [keras.layers.Dense(encoding_dim, activation=\"relu\")]\n",
    "dec_lays = [keras.layers.Dense(x_tr_1D.shape[1], activation=\"sigmoid\")]\n",
    "\n",
    "[autoencoder, encoder, decoder] = autoencoder_builder(inp_lay,\n",
    "                                                      enc_lays,\n",
    "                                                      dec_lays)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The training consists simply in minimizing the reconstruction error (measured through the MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisory = autoencoder.fit(x_tr_1D, x_tr_1D, epochs=10, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The images can be encoded/decoded applying the encoder/decoder subnetworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_te_1D)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "print(\"Prediction error: %.3f\" % autoencoder.evaluate(x_te_1D, x_te_1D, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following cell shows some examples of original and reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_te[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The encoder can be used to reduce the dimensionality of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(encoded_imgs[y_te==i, 0], encoded_imgs[y_te==i, 1], label=\"Digit %d\" % i)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* What happens if the process above is repeated setting the reduced dimension (`encoding_dim`) to $2$?\n",
    "* Is the AE expressive enough?\n",
    "* Is the resulting embedding better or worse?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define a Sparse AE, a regularization is used in the encoder so that the compressed data become sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 800\n",
    "\n",
    "inp_lay = keras.Input(shape=(x_tr_1D.shape[1],))\n",
    "enc_lays = [keras.layers.Dense(encoding_dim,\n",
    "                               activation=\"relu\",\n",
    "                               activity_regularizer=keras.regularizers.l1(1e-3))]\n",
    "dec_lays = [keras.layers.Dense(x_tr_1D.shape[1], activation=\"sigmoid\")]\n",
    "\n",
    "[autoencoder, encoder, decoder] = autoencoder_builder(inp_lay,\n",
    "                                                      enc_lays,\n",
    "                                                      dec_lays)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisory = autoencoder.fit(x_tr_1D, x_tr_1D, epochs=10, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_te_1D)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "print(\"Prediction error: %.3f\" % autoencoder.evaluate(x_te_1D, x_te_1D, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_te[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding is sparse, so a certain ratio of the coordinates are identically $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(encoded_imgs[y_te==i, 0], encoded_imgs[y_te==i, 1], label=\"Digit %d\" % i)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sparsity: %.2f%%\" % (100 * (encoded_imgs == 0).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* What happens if the regularization if set to $0$?\n",
    "* Is the AE compressing the information without regularization?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Deep AEs, a DNN is used both for the encoder and the decoder.\n",
    "Usually, both networks are symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_lay = keras.Input(shape=(784,))\n",
    "enc_lays = [\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"relu\"),\n",
    "]\n",
    "dec_lays = [\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(784, activation=\"sigmoid\"),\n",
    "]\n",
    "\n",
    "[autoencoder, encoder, decoder] = autoencoder_builder(inp_lay,\n",
    "                                                      enc_lays,\n",
    "                                                      dec_lays)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisory = autoencoder.fit(x_tr_1D, x_tr_1D, epochs=10, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_te_1D)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "print(\"Prediction error: %.3f\" % autoencoder.evaluate(x_te_1D, x_te_1D, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_te[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(encoded_imgs[y_te==i, 0], encoded_imgs[y_te==i, 1],label=\"Digit %d\" % i)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Taking into account that the reduced dimension is $2$, is this embedding better or worse than the ones above? Why?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell loads an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china = load_sample_images().images[0]\n",
    "china = china[:china.shape[0], :china.shape[0], :] / 255.0\n",
    "plt.imshow(china)\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution with Different Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different filters can be applied to the image above, to see their effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = []\n",
    "kv.append(np.array([[0, 0, 0],\n",
    "                    [0, 1, 0],\n",
    "                    [0, 0, 0]]))\n",
    "kv.append(np.array([[1, 1, 1],\n",
    "                    [0, 0, 0],\n",
    "                    [-1, -1, -1]]))\n",
    "kv.append(kv[-1].T)\n",
    "kv.append(np.array([[-1, -1, -1],\n",
    "                    [-1, 8, -1],\n",
    "                    [-1, -1, -1]]))\n",
    "kv.append(np.array([[0, -1, 0],\n",
    "                    [-1, 5, -1],\n",
    "                    [0, -1, 0]]))\n",
    "kv.append(1 / 256 * np.array([[1, 4, 6, 4, 1],\n",
    "                              [4, 16, 24, 16, 4],\n",
    "                              [6, 24, 36, 24, 6],\n",
    "                              [4, 16, 24, 16, 4],\n",
    "                              [1, 4, 6, 4, 1]]))\n",
    "lv = (\"Identity\", \"Edge H\", \"Edge V\", \"Edges\", \"Sharpen\", \"Gaussian\")\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "inp = tf.constant([china])\n",
    "for k, l in zip(kv, lv):\n",
    "    def kernel_init(shape, dtype=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[:, :, 0, 0] = k\n",
    "        kernel[:, :, 1, 1] = k\n",
    "        kernel[:, :, 2, 2] = k\n",
    "        return kernel\n",
    "\n",
    "    model = keras.Sequential([keras.layers.Conv2D(3,\n",
    "                                                  k.shape,\n",
    "                                                  kernel_initializer=kernel_init,\n",
    "                                                  input_shape=china.shape)])\n",
    "    model.build()\n",
    "    out = model.predict(inp)[0]\n",
    "    out = np.clip(out, 0, 1)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(china)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(k)\n",
    "    plt.title(\"Kernel (%s)\" % l)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(out)\n",
    "    plt.title(\"Convoluted Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* What effect will produce the filter corresponding to a $20 \\times 20$ matriz with a constant value of $\\frac{1}{400}$?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is modified so that each sample has dimension $28 \\times 28 \\times 1$, since the convolutional layers assume that the last dimension is the channel (in this case, there is only one channel since the image is in greyscale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_tr.reshape(-1, 28, 28, 1)\n",
    "x_te = x_te.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_tr = keras.utils.to_categorical(y_tr, num_classes=10)\n",
    "y_te = keras.utils.to_categorical(y_te, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Deep CNNs are easily defined in Keras using convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential()\n",
    "\n",
    "cnn.add(keras.layers.Conv2D(32, kernel_size=(3,3),  activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "cnn.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
    "cnn.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(keras.layers.Dropout(0.2))\n",
    "cnn.add(keras.layers.Flatten())\n",
    "cnn.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "cnn.add(keras.layers.Dropout(0.4))\n",
    "cnn.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is the standard of any DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn.fit(x_tr, y_tr, validation_split=0.75, batch_size=256, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evolution of the errors can show over-fitting problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy: %.3f%%\" % (100 * cnn.evaluate(x_te, y_te, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn.predict(x_te)\n",
    "y_te_t = np.argmax(y_te, axis=1)\n",
    "y_te_p = np.argmax(preds, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_te_t, y_te_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "preds = cnn.predict(x_te)\n",
    "y_te_t = np.argmax(y_te, axis=1)\n",
    "y_te_p = np.argmax(preds, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_te_t, y_te_p)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.axis(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple temporal series is generated next as an example to illustrate the RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(- 8 * np.pi, 8 * np.pi, 513)\n",
    "x = np.sin(x)\n",
    "\n",
    "y = x[1:].reshape(- 1, 1)\n",
    "x = x[:-1].reshape(- 1, 1, 1)\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.3, shuffle=False)\n",
    "plt.plot(range(len(y_tr.ravel())), y_tr.ravel())\n",
    "plt.plot(range(len(y_tr.ravel()), len(y_tr.ravel()) + len(y_te.ravel())), y_te.ravel())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides an LSTM layer, which includes as many LSTM units as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = keras.Sequential()\n",
    "rnn.add(keras.layers.LSTM(50, batch_input_shape=(1, 1, 1), stateful=True))\n",
    "rnn.add(keras.layers.Dense(1))\n",
    "\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network can be trained step by step, using batches of size $1$ and preserving the state of the network between batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_rnn = rnn.fit(x_tr, y_tr, epochs=10, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before predicting over the test set, the training set is used to initialize the state of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.reset_states()\n",
    "rnn.predict(x_tr, batch_size=1)\n",
    "preds_rnn = rnn.predict(x_te, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell illustrate the prediction of the RNN, and it depicts the input versus both the predicted output and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_te.ravel(), label=\"Real\")\n",
    "plt.plot(preds_rnn.ravel(), label=\"Pred\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x_te, y_te)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(x_te, preds_rnn)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* From the predictions above, does the RNN output depends only on the input (i.e., the value in the previous instant), or does it depend also on the context? Why?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator is a DNN that takes as input an image, and classifies it between real and generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    discriminator = keras.Sequential()\n",
    "\n",
    "    discriminator.add(keras.Input(shape=(28, 28, 1)))\n",
    "    discriminator.add(keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    discriminator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    discriminator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(keras.layers.Conv2D(128, kernel_size=4, strides=1, padding=\"same\"))\n",
    "    discriminator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(keras.layers.Flatten())\n",
    "    discriminator.add(keras.layers.Dropout(0.2))\n",
    "    discriminator.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "discriminator = create_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator is a DNN that takes as input a random vector, and produces as output an image of the desired size.\n",
    "Usually, its architecture is symmetric to that of the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    generator = keras.Sequential()\n",
    "    \n",
    "    generator.add(keras.Input(shape=(100, )))\n",
    "    generator.add(keras.layers.Dense(7 * 7 * 128))\n",
    "    generator.add(keras.layers.Reshape((7, 7, 128)))\n",
    "    generator.add(keras.layers.Conv2DTranspose(128, kernel_size=4, strides=1, padding=\"same\"))\n",
    "    generator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    generator.add(keras.layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    generator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    generator.add(keras.layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    generator.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    generator.add(keras.layers.Conv2D(1, kernel_size=5, padding=\"same\", activation=\"sigmoid\"))\n",
    "    \n",
    "    return generator\n",
    "\n",
    "generator = create_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GAN is simply the concatenation of the generator and the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    gan_input = keras.Input(shape=(100,))\n",
    "    gan = keras.Model(inputs=gan_input, outputs=discriminator(generator(gan_input)))\n",
    "    gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "    return gan\n",
    "\n",
    "gan = create_gan(discriminator, generator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function allows to visualize some generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(generator, dim=(5, 5), figsize=(5, 5)):\n",
    "    examples = np.prod(dim)\n",
    "    noise = np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples, 28, 28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        image = generated_images[i]\n",
    "\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trains the GAN, alternatively training the discriminator and the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iter = 51\n",
    "batch_size = 128\n",
    "\n",
    "(x_tr, y_tr), (x_te, y_te) = keras.datasets.mnist.load_data()\n",
    "x = x_tr[y_tr == 4].astype(\"float32\") / 255.\n",
    "\n",
    "for i in range(max_iter):\n",
    "\n",
    "    print(\"Iteration: %d\" % i, end=\"\\r\")\n",
    "    if (i % 10) == 0:\n",
    "        plot_generated_images(generator)\n",
    "\n",
    "    noise = np.random.normal(0, 1, [batch_size, 100])\n",
    "\n",
    "    generated_images = generator.predict(noise)\n",
    "    real_images = x[np.random.randint(low=0, high=x.shape[0], size=batch_size)]\n",
    "\n",
    "    X = np.concatenate([real_images, generated_images[:, :, :, 0]])\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "\n",
    "    y_dis = np.zeros(2 * batch_size)\n",
    "    y_dis[:batch_size] = 1.0\n",
    "\n",
    "    discriminator.trainable=True\n",
    "    discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "    noise = np.random.normal(0, 1, [batch_size, 100])\n",
    "    y_gen = np.ones(batch_size)\n",
    "\n",
    "    discriminator.trainable=False\n",
    "    gan.train_on_batch(noise, y_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Analyse the training of the GAN.\n",
    "* Why are the labels of the samples modified?\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "210.667px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
